{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqbsS-4SkIXD",
        "outputId": "5e438f95-96aa-4896-a2a0-d8285fdc83c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
            "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: orjson, jsonpointer, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.137 orjson-3.10.10 requests-toolbelt-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmxl_EDOkPGA",
        "outputId": "76d48ce8-6dcb-4c24-bd89-4e4246fda0c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.4)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.12)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.2.2)\n",
            "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFm_2dCglNmm",
        "outputId": "17345ddb-723e-4a47-b89a-1691c419ad32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.3.2-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting primp>=0.6.4 (from duckduckgo-search)\n",
            "  Downloading primp-0.6.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Downloading duckduckgo_search-6.3.2-py3-none-any.whl (27 kB)\n",
            "Downloading primp-0.6.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-6.3.2 primp-0.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZqkEkTNkXfo",
        "outputId": "eabb06d2-8bb8-4024-c0fa-f3ba5ae5605c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, openai\n",
            "Successfully installed jiter-0.6.1 openai-1.52.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import requests\n",
        "import base64\n",
        "import json\n",
        "import yfinance as yf\n",
        "import langchain\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "bRqh26ALj8OT"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = \"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\"\n",
        "llm=ChatOpenAI(temperature=0,model_name='gpt-4o',openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Bhs8fiK0j_qj"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zero_shot_agent=initialize_agent(\n",
        "#     llm=llm,\n",
        "#     agent=\"zero-shot-react-description\",\n",
        "#     tools=tools,\n",
        "#     verbose=True,\n",
        "#     max_iteration=4,\n",
        "#     return_intermediate_steps=False,\n",
        "#     handle_parsing_errors=True\n",
        "# )\n",
        "# zero_shot_agent.agent.llm_chain.prompt.template=stock_prompt"
      ],
      "metadata": {
        "id": "h6wDQ1yR5mzw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "companies = {\n",
        "    'Zomato': 'ZOMATO.NS',\n",
        "    'TCS': 'TCS.NS',\n",
        "    'Wipro': 'WIPRO.NS',\n",
        "    'Infosys': 'INFY.NS',\n",
        "    'HCL Technologies': 'HCLTECH.NS',\n",
        "    'Tata Motors': 'TATAMOTORS.NS',\n",
        "    'SBI': 'SBIN.NS',\n",
        "    'Maruti Suzuki': 'MARUTI.NS',\n",
        "    'Vodafone Idea': 'IDEA.NS',\n",
        "    'Reliance Industries': 'RELIANCE.NS',\n",
        "    'Bharti Airtel': 'BHARTIARTL.NS',\n",
        "    'ICICI Bank': 'ICICIBANK.NS',\n",
        "    'HDFC Bank': 'HDFCBANK.NS',\n",
        "    'Axis Bank': 'AXISBANK.NS',\n",
        "    'Tech Mahindra': 'TECHM.NS',\n",
        "    'Larsen & Toubro': 'LT.NS',\n",
        "    'Adani Enterprises': 'ADANIENT.NS',\n",
        "    'Adani Ports': 'ADANIPORTS.NS',\n",
        "    'Bajaj Finance': 'BAJFINANCE.NS',\n",
        "    'Hindustan Unilever': 'HINDUNILVR.NS',\n",
        "    'ITC': 'ITC.NS',\n",
        "    'Nestle India': 'NESTLEIND.NS',\n",
        "    'UltraTech Cement': 'ULTRACEMCO.NS',\n",
        "    'Asian Paints': 'ASIANPAINT.NS',\n",
        "    'Tata Steel': 'TATASTEEL.NS',\n",
        "    'JSW Steel': 'JSWSTEEL.NS',\n",
        "    'Power Grid Corporation': 'POWERGRID.NS',\n",
        "    'NTPC': 'NTPC.NS',\n",
        "    'Coal India': 'COALINDIA.NS',\n",
        "    'Tata Power': 'TATAPOWER.NS',\n",
        "    'Havells India': 'HAVELLS.NS',\n",
        "    'Britannia': 'BRITANNIA.NS',\n",
        "    'Titan Company': 'TITAN.NS',\n",
        "    'Godrej Consumer Products': 'GODREJCP.NS',\n",
        "    'Piramal Enterprises': 'PEL.NS',\n",
        "    'Mahindra & Mahindra': 'M&M.NS',\n",
        "    'Eicher Motors': 'EICHERMOT.NS',\n",
        "    'Hero MotoCorp': 'HEROMOTOCO.NS',\n",
        "    'Bajaj Auto': 'BAJAJ-AUTO.NS',\n",
        "    'Sun Pharmaceutical': 'SUNPHARMA.NS',\n",
        "    'Dr. Reddy’s Laboratories': 'DRREDDY.NS',\n",
        "    'Cipla': 'CIPLA.NS',\n",
        "    'Divi’s Laboratories': 'DIVISLAB.NS',\n",
        "    'Biocon': 'BIOCON.NS',\n",
        "    'Aurobindo Pharma': 'AUROPHARMA.NS',\n",
        "    'Motherson Sumi Systems': 'MOTHERSUMI.NS',\n",
        "    'Hindalco Industries': 'HINDALCO.NS',\n",
        "    'Grasim Industries': 'GRASIM.NS',\n",
        "    'Vedanta': 'VEDL.NS',\n",
        "    'ONGC':'ONGC.NS',\n",
        "}"
      ],
      "metadata": {
        "id": "4zEPLIRrCICJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "com=[]\n",
        "val=[]\n",
        "for i,j in companies.items():\n",
        "    com.append(i.lower())\n",
        "    val.append(j)\n",
        "companies=dict(zip(com,val))"
      ],
      "metadata": {
        "id": "xXFdiG3tIRvY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if openai_api_key:\n",
        "    llm=ChatOpenAI(temperature=0,model_name='gpt-4o',openai_api_key=openai_api_key)\n",
        "\n",
        "    #Get Historical Stock Closing Price for Last 1 Year\n",
        "    def get_stock_price(ticker):\n",
        "        if \".\" in ticker:\n",
        "            ticker = ticker.split(\".\")[0]\n",
        "        stock = yf.Ticker(companies[ticker])\n",
        "        df = stock.history(period=\"1y\")\n",
        "        df = df[[\"Close\",\"Volume\"]]\n",
        "        df.index=[str(x).split()[0] for x in list(df.index)]\n",
        "        df.index.rename(\"Date\",inplace=True)\n",
        "        return df.to_string()\n",
        "\n",
        "\n",
        "    #Get News From Web Scraping\n",
        "    def google_query(search_term):\n",
        "        if \"news\" not in search_term:\n",
        "            search_term = search_term+\" stock news\"\n",
        "        url = f\"https://www.google.com/search?q={search_term}\"\n",
        "        url = re.sub(r\"\\s\",\"+\",url)\n",
        "        return url\n",
        "\n",
        "    #Get Recent Stock News\n",
        "    def get_recent_stock_news(company_name):\n",
        "        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
        "        g_query = google_query(company_name)\n",
        "        res=requests.get(g_query,headers=headers).text\n",
        "        soup = BeautifulSoup(res,\"html.parser\")\n",
        "        news=[]\n",
        "        for n in soup.find_all(\"div\",\"n0jPhd ynAwRc tNxQIb nDgy9d\"):\n",
        "            news.append(n.text)\n",
        "        for n in soup.find_all(\"div\",\"IJl0Z\"):\n",
        "            news.append(n.text)\n",
        "\n",
        "        if len(news) > 6:\n",
        "            news = news[:4]\n",
        "        else:\n",
        "            news = news\n",
        "\n",
        "        news_string=\"\"\n",
        "        for i,n in enumerate(news):\n",
        "            news_string+=f\"{i}. {n}\\n\"\n",
        "        top5_news=\"Recent News:\\n\\n\"+news_string\n",
        "\n",
        "        return top5_news\n",
        "\n",
        "    #Get Financial Statements\n",
        "    def get_financial_statements(ticker):\n",
        "        if \".\" in ticker:\n",
        "            ticker = ticker.split(\".\")[0]\n",
        "        else:\n",
        "            ticker=ticker\n",
        "        company = yf.Ticker(companies[ticker])\n",
        "        balance_sheet = company.balance_sheet\n",
        "        if balance_sheet.shape[1]>3:\n",
        "            balance_sheet = balance_sheet.iloc[:,:3]\n",
        "        balance_sheet = balance_sheet.dropna(how=\"any\")\n",
        "        balance_sheet = balance_sheet.to_string()\n",
        "        return balance_sheet\n",
        "\n",
        "    #Initialize DuckDuckGo Search Engine\n",
        "    search=DuckDuckGoSearchRun()\n",
        "    tools = [\n",
        "    Tool(\n",
        "        name=\"Stock Ticker Search\",\n",
        "        func=search.run,\n",
        "        description=\"Use only when you need to get stock ticker from internet, you can also get recent stock related news. Dont use it for any other analysis or task\"\n",
        "\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Get Stock Historical Price\",\n",
        "        func = get_stock_price,\n",
        "        description=\"Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the stock ticker to it\"\n",
        "\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Get Recent News\",\n",
        "        func= get_recent_stock_news,\n",
        "        description=\"Use this to fetch recent news about stocks\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Get Financial Statements\",\n",
        "        func=get_financial_statements,\n",
        "        description=\"Use this to get financial statement of the company. With the help of this data company's historic performance can be evaluated. You should input stock ticker to it\"\n",
        "    )\n",
        "    ]\n",
        "\n",
        "    zero_shot_agent=initialize_agent(\n",
        "        llm=llm,\n",
        "        agent=\"zero-shot-react-description\",\n",
        "        tools=tools,\n",
        "        verbose=True,\n",
        "        max_iteration=4,\n",
        "        return_intermediate_steps=False,\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "\n",
        "    #Adding predefine evaluation steps in the agent Prompt\n",
        "    stock_prompt=\"\"\"You are a financial advisor. Give stock recommendations for given query.\n",
        "    Everytime first you should identify the company name and get the stock ticker symbol for the stock.\n",
        "    Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "    Get Stock Historical Price: Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the stock ticker to it\n",
        "    Stock Ticker Search: Use only when you need to get stock ticker from internet, you can also get recent stock related news. Dont use it for any other analysis or task\n",
        "    Get Recent News: Use this to fetch recent news about stocks\n",
        "    Get Financial Statements: Use this to get financial statement of the company. With the help of this data company's historic performance can be evaluaated. You should input stock ticker to it\n",
        "\n",
        "    steps-\n",
        "    Note- if you fail in satisfying any of the step below, Just move to next one\n",
        "    1) Get the company name and search for the \"company name + stock ticker\" on internet. Dont hallucinate extract stock ticker as it is from the text. Output- stock ticker. If stock ticker is not found, stop the process and output this text: This stock does not exist\n",
        "    2) Use \"Get Stock Historical Price\" tool to gather stock info. Output- Stock data\n",
        "    3) Get company's historic financial data using \"Get Financial Statements\". Output- Financial statement\n",
        "    4) Use this \"Get Recent News\" tool to search for latest stock related news. Output- Stock news\n",
        "    5) Analyze the stock based on gathered data and give detailed analysis for investment choice. provide numbers and reasons to justify your answer. Output- Give a single answer if the user should buy,hold or sell. You should Start the answer with Either Buy, Hold, or Sell in Bold after that Justify.\n",
        "\n",
        "    Use the following format:\n",
        "\n",
        "    Question: the input question you must answer\n",
        "    Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
        "    Action: the action to take, should be one of [Get Stock Historical Price, Stock Ticker Search, Get Recent News, Get Financial Statements]\n",
        "    Action Input: the input to the action\n",
        "    Observation: the result of the action\n",
        "    ... (this Thought/Action/Action Input/Observation can repeat N times, if Thought is empty go to the next Thought and skip Action/Action Input and Observation)\n",
        "    Thought: I now know the final answer\n",
        "    Final Answer: the final answer to the original input question\n",
        "    Begin!\n",
        "\n",
        "    Question: {input}\n",
        "    Thought:{agent_scratchpad}\"\"\"\n"
      ],
      "metadata": {
        "id": "iBDdu0Fn-zQO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain, PromptTemplate\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"What is the stock price for {company}?\"\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"company\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "# Example of stock_prompt input\n",
        "stock_prompt = {\"company\": companies['tcs']}\n",
        "\n",
        "# Use LLMChain with your preferred LLM\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "# Run the chain with input\n",
        "output = llm_chain.run(stock_prompt)\n",
        "\n",
        "# Print the result\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv-WPpt9lQfI",
        "outputId": "2e70b93e-dd28-48a6-e1b1-0592a06c2cf6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm unable to provide real-time stock prices or any other live data. To find the current stock price for TCS.NS (Tata Consultancy Services on the National Stock Exchange of India), you can check financial news websites, stock market apps, or platforms like Google Finance, Yahoo Finance, or Bloomberg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_stock_data(company_name):\n",
        "  company_name=company_name.lower()\n",
        "  histroical_price = get_stock_price(company_name)\n",
        "  financial_statements = get_financial_statements(company_name)\n",
        "  recent_news = get_recent_stock_news(company_name)\n",
        "  return histroical_price, financial_statements, recent_news"
      ],
      "metadata": {
        "id": "ft9VjMLAGqCF"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to analyze data and make a recommendation\n",
        "def analyze_data(historical_price, financial_statements, recent_news):\n",
        "    \"\"\"\n",
        "    Analyze data and determine a buy/hold/sell recommendation.\n",
        "    Arguments:\n",
        "        - historical_price: List or dataframe of stock prices.\n",
        "        - financial_statements: Parsed financial statement data.\n",
        "        - recent_news: Parsed recent news articles.\n",
        "    Returns:\n",
        "        - recommendation: Buy/Hold/Sell recommendation.\n",
        "        - justification: Justification for the recommendation.\n",
        "    \"\"\"\n",
        "    # Example placeholder analysis logic (replace with actual financial analysis)\n",
        "\n",
        "    # Check if the stock price has been steadily increasing\n",
        "    if historical_price and historical_price[-1] > historical_price[0]:\n",
        "        recommendation = \"Buy\"\n",
        "        justification = \"Stock price has shown consistent growth over the past year.\"\n",
        "    # Check if there is negative sentiment in recent news\n",
        "    elif \"scandal\" in recent_news.lower():\n",
        "        recommendation = \"Sell\"\n",
        "        justification = \"Recent news suggests negative sentiment due to potential scandals.\"\n",
        "    else:\n",
        "        recommendation = \"Hold\"\n",
        "        justification = \"More data and analysis is needed for a definitive recommendation.\"\n",
        "\n",
        "    return recommendation, justification"
      ],
      "metadata": {
        "id": "qE7rCCeWr2Om"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_price, financial_statements, recent_news = get_all_stock_data('tata steel')"
      ],
      "metadata": {
        "id": "qAKy9f7nFxsA"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i have historical price ,recent news and financial statement of a stock and build prompt and return analysis of it using llm\n",
        "\n",
        "from langchain.agents import Tool, initialize_agent\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "def analyze_stock(company_name):\n",
        "    historical_price, financial_statements, recent_news = get_all_stock_data(company_name)\n",
        "\n",
        "    # Construct the prompt for the LLM\n",
        "    prompt = f\"\"\"Analyze the following stock data and provide a buy/sell/hold recommendation.\n",
        "\n",
        "    **Historical Price:**\n",
        "    ```\n",
        "    {historical_price}\n",
        "    ```\n",
        "\n",
        "    **Financial Statements:**\n",
        "    ```\n",
        "    {financial_statements}\n",
        "    ```\n",
        "\n",
        "    **Recent News:**\n",
        "    ```\n",
        "    {recent_news}\n",
        "    ```\n",
        "\n",
        "    Provide a concise recommendation (Buy, Sell, or Hold) followed by a detailed justification.  Use numbers and specific details from the data to support your reasoning.\n",
        "    \"\"\"\n",
        "\n",
        "    # Use the LLM to generate the analysis\n",
        "    llm = ChatOpenAI(temperature=0, model_name='gpt-4o', openai_api_key=openai_api_key)  # Use a suitable model\n",
        "    analysis = llm.predict(prompt)\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "# Example usage\n",
        "company_to_analyze = \"tata steel\"  # Replace with the desired company\n",
        "analysis_result = analyze_stock(company_to_analyze)\n",
        "print(f\"Analysis for {company_to_analyze}:\\n{analysis_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCncb-k_KvHk",
        "outputId": "72f3ba8e-654f-421a-a16e-7a6a5750989f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis for tata steel:\n",
            "Based on the provided data, I would recommend a **Hold** position for Tata Steel. Here is the detailed justification:\n",
            "\n",
            "### Stock Price Analysis:\n",
            "1. **Recent Price Trend**: The stock price has shown significant volatility over the past few months. It reached a high of 179.94 on June 21, 2024, and then experienced a decline, reaching a low of 148.77 on October 23, 2024. The recent price as of October 23, 2024, is 148.78, which is a decline from the highs seen earlier in the year.\n",
            "\n",
            "2. **Volume Analysis**: There have been periods of high trading volume, such as on March 1, 2024, with 123,709,943 shares traded, indicating strong investor interest. However, recent volumes have been lower, suggesting reduced trading activity.\n",
            "\n",
            "### Financial Statement Analysis:\n",
            "1. **Debt Levels**: The company has a high level of net debt, which has increased from 532,240,000,000 in 2022 to 744,930,800,000 in 2024. This increase in debt could be a concern, especially if interest rates rise or if the company faces challenges in generating cash flow.\n",
            "\n",
            "2. **Equity and Assets**: The tangible book value and stockholders' equity have decreased over the years, indicating potential challenges in maintaining asset value and equity strength. The tangible book value decreased from 1,084,146,400,000 in 2022 to 848,514,400,000 in 2024.\n",
            "\n",
            "3. **Working Capital**: The working capital has turned negative, from 19,686,100,000 in 2022 to -278,552,400,000 in 2024, which could indicate liquidity issues.\n",
            "\n",
            "### Recent News:\n",
            "1. **Profit Announcement**: The company reported a profit of Rs 9,84,60,000 in Q2, which is a positive sign. However, the stock price is still below Rs 500, indicating that the market may not be fully confident in the company's future prospects.\n",
            "\n",
            "2. **Market Sentiment**: The recent news mentions a slight decline in Tata Steel's share price and the Nifty index, suggesting a cautious market sentiment.\n",
            "\n",
            "### Conclusion:\n",
            "- **Positives**: The company has reported profits, and there is investor interest as seen in high trading volumes earlier in the year.\n",
            "- **Negatives**: High debt levels, declining equity, negative working capital, and recent price declines suggest caution.\n",
            "\n",
            "Given these factors, a **Hold** recommendation is appropriate. Investors should monitor the company's financial health, particularly its ability to manage debt and improve liquidity, while also keeping an eye on market conditions and any further news that could impact the stock price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i'm going to deploy this llm model on streamlit application so build a pipeline if needed and save it. so that i can directly use it on streamlit application\n",
        "\n",
        "import joblib\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "def analyze_stock(company_name):\n",
        "    historical_price, financial_statements, recent_news = get_all_stock_data(company_name)\n",
        "\n",
        "    # Construct the prompt for the LLM\n",
        "    prompt = f\"\"\"Analyze the following stock data and provide a buy/sell/hold recommendation.\n",
        "\n",
        "    **Historical Price:**\n",
        "    ```\n",
        "    {historical_price}\n",
        "    ```\n",
        "\n",
        "    **Financial Statements:**\n",
        "    ```\n",
        "    {financial_statements}\n",
        "    ```\n",
        "\n",
        "    **Recent News:**\n",
        "    ```\n",
        "    {recent_news}\n",
        "    ```\n",
        "\n",
        "    Provide a concise recommendation (Buy, Sell, or Hold) followed by a detailed justification.  Use numbers and specific details from the data to support your reasoning.\n",
        "    \"\"\"\n",
        "\n",
        "    # Use the LLM to generate the analysis\n",
        "    llm = ChatOpenAI(temperature=0, model_name='gpt-4o', openai_api_key=openai_api_key)  # Use a suitable model\n",
        "    analysis = llm.predict(prompt)\n",
        "\n",
        "    return analysis\n",
        "\n",
        "# Save the pipeline (functions and LLM)\n",
        "pipeline = {\n",
        "    'get_all_stock_data': get_all_stock_data,\n",
        "    'analyze_stock': analyze_stock,\n",
        "    'openai_api_key': openai_api_key, # store api key securely\n",
        "    'companies': companies # store companies dict\n",
        "}\n",
        "\n",
        "joblib.dump(pipeline, 'stock_analysis_pipeline.joblib')\n",
        "\n",
        "# Example usage (for testing before deploying to Streamlit)\n",
        "# company_to_analyze = \"tata steel\"\n",
        "# analysis_result = analyze_stock(company_to_analyze)\n",
        "# print(f\"Analysis for {company_to_analyze}:\\n{analysis_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSebBIbANAGi",
        "outputId": "ed278266-8ed0-4341-c479-9cbbe19ba18d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stock_analysis_pipeline.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_EtHdOTNek0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}